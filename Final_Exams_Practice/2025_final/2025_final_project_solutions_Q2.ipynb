{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4baf963",
   "metadata": {},
   "source": [
    "# 2025 Spring ORF307 Final Project Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2420c4d",
   "metadata": {},
   "source": [
    "Instructor: B. Stellato\n",
    "\n",
    "AIs: Yanjun Liu, Qishuo Yin, Chenyu Yu, and Kaiwen Zhang\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac556b07",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "**Exam files:** the exam files are available to download at [THIS LINK.](https://www.dropbox.com/scl/fo/b6an98pypucpvdhb81osz/AHSPIHMuLOtnttr-CDG6ZZY?rlkey=6wph0csyr9gldp2lo7akkx4ln&st=ckxp1xua&dl=0)\n",
    "\n",
    "**Date and time:** From May 8, 2025 at 00:01 am to May 11, 2025 at 7:00pm.\n",
    "\n",
    "- Total time after download: 24 hours. No late submissions allowed. Note that the deadline is either 24 hours after download, or May 11, 2025 at 7:00pm, **whichever comes first**.\n",
    "\n",
    "## Exam Rules\n",
    "- You are allowed to use all course materials on the midterm (lecture notes, books, precept materials, code, and homeworks). But you cannot use internet to search for answers.\n",
    "- You have to justify all your answers. If you use code from the course materials, you have to explain what each step means.\n",
    "- You cannot communicate with anyone during the exam.\n",
    "- No late submissions allowed. Make sure your submission goes through on time. You can resubmit as many times as you like until your time expires.\n",
    "- The exam is to be submitted electronically on Gradescope before 7:00pm on the final day."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34ddc29",
   "metadata": {},
   "source": [
    "# Final Exam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dde275a-2a25-4947-a756-8ac4c91cf33b",
   "metadata": {},
   "source": [
    "## Introduction \n",
    "\n",
    "For this final project, you will work with the Fashion MNIST dataset including thousands of images of clothes, which we have provided in CSV format. \n",
    "\n",
    "You will work with a pre-processed version of this dataset where each label is +1 if the image is a shirt and -1 otherwise.\n",
    "\n",
    "To load the dataset, ensure the following files are in a folder called `data/` in your working directory: `X_train.csv`, `y_train.csv`, `X_test.csv`, `y_test.csv`. Then run the following code to import the packages and load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d769c1d-b92e-4bd9-9813-ca9dedd37f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(precision=4)  # Print few decimal places\n",
    "np.set_printoptions(suppress=True)  # Suppress scientific notation\n",
    "import cvxpy as cp\n",
    "import pandas as pd\n",
    "from numpy.linalg import cholesky as llt\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c304ea7b-76c2-48ff-8498-c024e4ad5e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Fashion MNIST dataset\n",
      "--------------------------------------------------\n",
      "Number of features: 784  (28 x 28 pixels)\n",
      "Training set:\n",
      "  • Samples: 5000\n",
      "  • Value range: [0.00, 255.00]\n",
      "Test set:\n",
      "  • Samples: 1000\n",
      "  • Value range: [0.00, 255.00]\n"
     ]
    }
   ],
   "source": [
    "X_train = pd.read_csv(f\"data/X_train.csv\").values\n",
    "y_train = pd.read_csv(f\"data/y_train.csv\").values.ravel()\n",
    "X_test = pd.read_csv(f\"data/X_test.csv\").values\n",
    "y_test = pd.read_csv(f\"data/y_test.csv\").values.ravel()\n",
    "\n",
    "n_train, m = X_train.shape\n",
    "n_test, m = X_test.shape\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(\"Fashion MNIST dataset\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Number of features: {m}  ({int(np.sqrt(m))} x {int(np.sqrt(m))} pixels)\")\n",
    "print(f\"Training set:\")\n",
    "print(f\"  • Samples: {n_train}\")\n",
    "print(f\"  • Value range: [{X_train.min():.2f}, {X_train.max():.2f}]\")\n",
    "print(f\"Test set:\")\n",
    "print(f\"  • Samples: {n_test}\")\n",
    "print(f\"  • Value range: [{X_train.min():.2f}, {X_train.max():.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127658a5-975f-44e9-ab95-79ba834ff61f",
   "metadata": {},
   "source": [
    "Now, let's visualize a couple of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7028a681-fefc-48ee-ad05-7aaca525058a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_images(*images):\n",
    "    n_images = len(images)\n",
    "    fig, axes = plt.subplots(1, n_images, figsize=(14,6))\n",
    "    if n_images == 1:\n",
    "        axes = [axes]   \n",
    "    for i, (ax, img) in enumerate(zip(axes, images)):\n",
    "        img_reshaped = img.reshape(28, 28)\n",
    "        im = ax.imshow(img_reshaped, cmap='gray')\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e33c88ae-e1ad-4931-82ec-ab51436c7904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "example_boot = X_train[3]\n",
    "example_shirt = X_train[0]\n",
    "visualize_images(example_boot, example_shirt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ea2986-d059-4c87-97f0-d0686d1a5d12",
   "metadata": {},
   "source": [
    "# 1. (35 points) Build a Support Vector Machine to correctly classify shirts\n",
    "\n",
    "1. (5 points) Formulate a Support Vector Machine problem to find a hyperplane $(a, b)$ where $a \\in \\mathbf{R}^m$ and $b \\in \\mathbf{R}$ to classify shirts. Given sample $x^{(i)}$, your hyperplane should be $a^Tx^{(i)} + b > 0$ if label $y^{(i)} = 1$ (shirt) or $a^Tx^{(i)} + b < 0$ if label $y^{(i)} = -1$ (not a shirt). You should include a second term in the objective, weighted by parameters $\\lambda > 0$ to regularize the $\\ell_1$-norm of $a$.\n",
    "\n",
    "    Note: Remember to normalize the misclassification error by the total number of training samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b91f53",
   "metadata": {
    "vscode": {
     "languageId": "latex"
    }
   },
   "source": [
    "\\[\n",
    "\\begin{array}{ll@{}ll}\n",
    "\\min\\limits_{a, b, \\xi} & \\displaystyle \\frac{1}{N} \\sum_{i=1}^{N} \\xi^{(i)} + \\lambda \\|a\\|_1 & & \\\\\n",
    "\\text{s.t.} & y^{(i)}(a^T x^{(i)} + b) \\geq 1 - \\xi^{(i)}, & \\quad \\forall i = 1, \\dots, N, & \\\\\n",
    "            & \\xi^{(i)} \\geq 0, & \\quad \\forall i = 1, \\dots, N. &\n",
    "\\end{array}\n",
    "\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dfca8c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM:\n",
    "    def __init__(self, lambda_val):\n",
    "        \"\"\"\n",
    "        Initialize SVM with L1 regularization parameter.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        lambda_val : float\n",
    "            Regularization strength (must be >= 0).\n",
    "        \"\"\"\n",
    "        if lambda_val < 0:\n",
    "            raise ValueError(\"lambda_val must be non-negative.\")\n",
    "        self.lambda_val = lambda_val\n",
    "        self.a = None\n",
    "        self.b = None\n",
    "\n",
    "    def fit(self, X, y, solver=cp.CLARABEL, verbose=False):\n",
    "        \"\"\"\n",
    "        Fit the SVM model to the training data using convex optimization.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : np.ndarray, shape (n_samples, n_features)\n",
    "            Training feature matrix.\n",
    "        y : np.ndarray, shape (n_samples,)\n",
    "            Training labels (±1).\n",
    "        solver : cvxpy solver, optional\n",
    "            Solver to use (default: CLARABEL).\n",
    "        verbose : bool, optional\n",
    "            Whether to print solver progress (default: False).\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        a : np.ndarray\n",
    "            Learned weight vector.\n",
    "        b : float\n",
    "            Learned bias term.\n",
    "        \"\"\"\n",
    "        n_samples = X.shape[0]\n",
    "        a = cp.Variable(X.shape[1])\n",
    "        b = cp.Variable()\n",
    "        \n",
    "        # Hinge loss (average per sample) + L1 regularization\n",
    "        hinge_loss = cp.sum(cp.pos(1 - cp.multiply(y, X @ a + b))) / n_samples\n",
    "        objective = cp.Minimize(hinge_loss + self.lambda_val * cp.norm(a, 1))\n",
    "        \n",
    "        # Solve the problem\n",
    "        problem = cp.Problem(objective)\n",
    "        problem.solve(solver=solver, verbose=verbose)\n",
    "        \n",
    "        self.a = a.value\n",
    "        self.b = b.value\n",
    "        \n",
    "        return self.a, self.b\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict labels for input data.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : np.ndarray, shape (n_samples, n_features)\n",
    "            Input feature matrix.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        y_pred : np.ndarray, shape (n_samples,)\n",
    "            Predicted labels (±1).\n",
    "        \"\"\"\n",
    "        if self.a is None or self.b is None:\n",
    "            raise RuntimeError(\"Model not trained. Call fit() first.\")\n",
    "        return np.sign(X @ self.a + self.b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa09013-6958-4308-9bf9-af577b7b7470",
   "metadata": {},
   "source": [
    "2. (7 points) Run a cross-validation procedure: solve the problem using CVXPY and CLARABEL solver for $\\lambda = (0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05)$ and pick the model that has the lowest test error.\n",
    "\n",
    "    Note, these problems are quite large so it may take a few seconds to solve them. (you may use the argument `verbose=True` to print out the solver progress).\n",
    "\n",
    "    Here is a utility function to check the test error. For example, you can use it as `error(X_test, y_test, a, b)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "46880e87-e38f-4b64-a1f9-ea4fd21b6534",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(X, y, a, b):\n",
    "    y_pred = np.sign(X @ a + b)\n",
    "    return np.mean(y_pred != y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28c65201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001    0.192\n",
       "0.0005    0.197\n",
       "0.0010    0.197\n",
       "0.0050    0.189\n",
       "0.0100    0.180\n",
       "0.0500    0.172\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_vals = [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05]\n",
    "\n",
    "svms = {}\n",
    "test_errors = {}\n",
    "\n",
    "for lambda_val in lambda_vals:\n",
    "    svm = SVM(lambda_val)\n",
    "    svm.fit(X_train, y_train)\n",
    "    svms[lambda_val] = svm\n",
    "    test_errors[lambda_val] = error(X_test, y_test, svm.a, svm.b)\n",
    "\n",
    "errors = pd.Series(test_errors)\n",
    "errors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35900140-4d89-45b2-b245-e976871d5ddc",
   "metadata": {},
   "source": [
    "3. (7 points) Write the training problem as a linear program in inequality form (get rid of all norms in the formulation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c244b64-5989-49a4-8655-1d5745a15156",
   "metadata": {},
   "source": [
    "4. (7 points) Write the dual problem and call the dual variables corresponding to the misclassified points as $z \\in \\mathbf{R}^{\\rm n\\_train}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416e371d-9ef3-476f-95fe-6f05ec872289",
   "metadata": {},
   "source": [
    "5. (7 points) Identify which points are misclassified using the dual variables $z$. Visualize the images corresponding to the 5 largest dual variables. How do they compare to a shirt image below?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6631db87-fa13-4e4b-a39a-9e4913f28930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk4AAAJOCAYAAABBWYj1AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAFOFJREFUeJzt3U2IZHe9xvH/qarp7nnrztu0Y0gHCaPgCxokJDBBg7pRcFwIZmcEXYi4U9CFuHTlyo2IuBAh4sK9G0WziIiYxWDcqJCBaSI2ZMbuycz0S9U5l1neS27yXPLr22e6P5/14eFU1alT3z4JSTcMw9AAAHhHk3c+BACAe4QTAEBIOAEAhIQTAEBIOAEAhIQTAEBIOAEAhIQTAEBolhzU9317/fXX2/nz51vXdek2AMDo3ftvgd+6das9+uijbTKZvPtwuhdNGxsbVecHADA6169fb4899ti7/0d19540AQAcZ0nvRE+c/OO5GofxPvpfDQLA/9/vtH85HAAgJJwAAELCCQAgJJwAAELCCQAgJJwAAELCCQAgJJwAAELCCQAgJJwAAELCCQAgJJwAAELCCQAgJJwAAELCCQAgJJwAAELCCQAgNEsP5N0bhqGdNMvLy+Wb3/3ud0v3vvWtb7VqP/7xj0v3fvnLX5bufelLX2rVzp49W7o3n89L9yaT+r8Tt7e3S/deeuml0r0f/vCHrdprr71WuvfVr361dG93d7d0D/4nT5wAAELCCQAgJJwAAELCCQAgJJwAAELCCQAgJJwAAELCCQAgJJwAAELCCQAgJJwAAELCCQAgJJwAAELCCQAgJJwAAELCCQAgJJwAAELCCQAgJJwAAELCCQAg1A3DMLzTQTs7O21tbS3d5H8xm83KN+fzeenegw8+WLr3xz/+sVW7ePFi6V7f963a1tZW6d6VK1dK9/75z3+W7lHj5z//eeneF77whVbt4OCgdG93d7d07ytf+Uqr9oc//KF0r+u6Vi34KT/ScxyKz++wbG9vt9XV1bc9xhMnAICQcAIACAknAICQcAIACAknAICQcAIACAknAICQcAIACAknAICQcAIACAknAICQcAIACAknAICQcAIACAknAICQcAIACAknAICQcAIACAknAIBQNwzD8E4H7ezstLW1tXST+9ivfvWr0r3Pfvazrdr169dL96bTaat2+vTp0r2HH364dO/Xv/51q/anP/2pdO/GjRulex/60Idaterre2Njo3TvzTffbNXm83np3vr6eune3//+91btE5/4RBu7yaT2OUjf9+0k2t7ebqurq297jCdOAAAh4QQAEBJOAAAh4QQAEBJOAAAh4QQAEBJOAAAh4QQAEBJOAAAh4QQAEBJOAAAh4QQAEBJOAAAh4QQAEBJOAAAh4QQAEBJOAAAh4QQAEBJOAAChbhiG4Z0O2tnZaWtra+2kmU6npXuLxaKN3V//+tfSvcO4bubzeele8BX4Pzs4OCjdO336dOne448/Xrp3Ut28ebN07/r166V7Z8+ebWNXfV984IEHWrVnnnmmdO/atWut2qlTp0Z9D7tfbG9vt9XV1bc9xhMnAICQcAIACAknAICQcAIACAknAICQcAIACAknAICQcAIACAknAICQcAIACAknAICQcAIACAknAICQcAIACAknAICQcAIACAknAICQcAIACAknAICQcAIACM3SA0+iyaS2KxeLRat27ty50r0LFy6U7m1vb7eT9jkfxubOzk7p3tWrV1u1+Xxeutd1XRu76XRaunfmzJnSvYODg1ZteXl51NfNyspKq/bJT36ydO/atWutWt/35Zu8NU+cAABCwgkAICScAABCwgkAICScAABCwgkAICScAABCwgkAICScAABCwgkAICScAABCwgkAICScAABCwgkAICScAABCwgkAICScAABCwgkAICScAABCs/TAk6jv+zZ2Tz75ZOne0tJS6d50Om3Vqs/x9u3brdp8Pi/dW1lZKd0bhqF07zA2q6+dxWLRxv6aq+85p06damN/zdXneBif86c+9anSvV/84hetWtd1o94bDuGec1Q8cQIACAknAICQcAIACAknAICQcAIACAknAICQcAIACAknAICQcAIACAknAICQcAIACAknAICQcAIACAknAICQcAIACAknAICQcAIACAknAICQcAIACM3SAxmnJ598snRvOp22sTt16lTpXtd1rdrp06dL94ZhKN2bTOr/Zqo+x2pLS0vlm33fl+4tFotRn99hfP+qVb+H93zwgx9sYzefz4/6FE4MT5wAAELCCQAgJJwAAELCCQAgJJwAAELCCQAgJJwAAELCCQAgJJwAAELCCQAgJJwAAELCCQAgJJwAAELCCQAgJJwAAELCCQAgJJwAAELCCQAgJJwAAELCCQAgNEsPPImGYWhj95GPfKR0r+u60r2+71u1yWQy6r3DeN3Vn8v9cG1XWywW5ZvV7+NsVntL3t7ebtUuXbpUunfjxo3R33Pe9773tZOm+r7YH8LnclQ8cQIACAknAICQcAIACAknAICQcAIACAknAICQcAIACAknAICQcAIACAknAICQcAIACAknAICQcAIACAknAICQcAIACAknAICQcAIACAknAICQcAIACM3SA0+ivu/b2F26dKl0b7FYlO5NJvVt/sgjj5Tu3bp1q4392um6ro3dMAztpKn+XKq/f9PptI3d8vJy6d7+/n6rtre3V7p35syZVu3OnTujvnb6++D3NOWJEwBASDgBAISEEwBASDgBAISEEwBASDgBAISEEwBASDgBAISEEwBASDgBAISEEwBASDgBAISEEwBASDgBAISEEwBASDgBAISEEwBASDgBAISEEwBASDgBAIRm7Rjpuq50bxiGNnYf+MAHRv2al5eXW7Xqc+z7vlWbTPxNctzvD4d17VRaXV0t3/zLX/5SuvfhD3+4jd1DDz1UuvfEE0+0aq+++uqJuraPkrs7AEBIOAEAhIQTAEBIOAEAhIQTAEBIOAEAhIQTAEBIOAEAhIQTAEBIOAEAhIQTAEBIOAEAhIQTAEBIOAEAhIQTAEBIOAEAhIQTAEBIOAEAhIQTAEBo1o6RyaS2AxeLRRu727dvl+4tLS2V7p05c6ZVe+WVV0r3zp8/36qdOnWqjVnXdW3shmFoY1f9Ps7n89K9tbW1Vm1zc7N074knnhj1Peye2az2p/Izn/lMq/bqq6+Wb/LWPHECAAgJJwCAkHACAAgJJwCAkHACAAgJJwCAkHACAAgJJwCAkHACAAgJJwCAkHACAAgJJwCAkHACAAgJJwCAkHACAAgJJwCAkHACAAgJJwCAkHACAAjN0gN599bX18s3L168WLp39+7d0r3z58+3aq+88krp3pUrV1q1/f390r2+70v3JpP6v5mqz7F6r+u6NnbVn8t0Om1jv7ar7zmnT59u1Q4ODkr3nnvuuVbtRz/6UeneYrEo3TtOPHECAAgJJwCAkHACAAgJJwCAkHACAAgJJwCAkHACAAgJJwCAkHACAAgJJwCAkHACAAgJJwCAkHACAAgJJwCAkHACAAgJJwCAkHACAAgJJwCAkHACAAgJJwCA0Cw9kHfvmWeeKd9cWVkp3dvb2yvde+ONN1q11157rXTv4YcfbtU2NzfbmPV9f9SnwFvouq6N3XQ6HfU9Zzar/1nb398v3fvYxz7WTpruEK7tYRjaUfDECQAgJJwAAELCCQAgJJwAAELCCQAgJJwAAELCCQAgJJwAAELCCQAgJJwAAELCCQAgJJwAAELCCQAgJJwAAELCCQAgJJwAAELCCQAgJJwAAELCCQAgNGvHyGKxaGP2jW98o3xzb2+vdO/s2bOle9evX2/Vdnd3S/dWVlZatfl8Xrq3vLw86vO7ZzKp/Tus67p20vR938buwoULpXtXr14t3fvoRz/aqm1ubpbuDcPQTpruEL7PR/U+euIEABASTgAAIeEEABASTgAAIeEEABASTgAAIeEEABASTgAAIeEEABASTgAAIeEEABASTgAAIeEEABASTgAAIeEEABASTgAAIeEEABASTgAAIeEEABCatSMynU7LNxeLRRuzz33uc+WbW1tbpXvr6+ule1evXm3Vzp0718au67rSvclkMurzO6mGYSjdW1paKt07ODho1S5cuFC699Of/rR078tf/nIb+2/LI4880qo9++yzpXsvv/xy6d5x4okTAEBIOAEAhIQTAEBIOAEAhIQTAEBIOAEAhIQTAEBIOAEAhIQTAEBIOAEAhIQTAEBIOAEAhIQTAEBIOAEAhIQTAEBIOAEAhIQTAEBIOAEAhIQTAEBIOAEAhGbpgSfR5cuXS/feeOONVm0+n7cx29raKt/c2Ngo3dvb22vVJpPav0kWi0Ubu67r2klT/Zqrr5tbt261au9973tHf18cu+l0Wr75xS9+sXTv5ZdfLt3r+74dF544AQCEhBMAQEg4AQCEhBMAQEg4AQCEhBMAQEg4AQCEhBMAQEg4AQCEhBMAQEg4AQCEhBMAQEg4AQCEhBMAQEg4AQCEhBMAQEg4AQCEhBMAQEg4AQCEZu2IDMPQxu5rX/ta6d50Om3VFotFG7OLFy+Wb1a/j7u7u63aZDIZ9d5hfP+qN7uua2NXfY5934/+c15ZWSnde/bZZ0f/mpeWlkr39vb2WrXPf/7zpXvf/va3S/eOE0+cAABCwgkAICScAABCwgkAICScAABCwgkAICScAABCwgkAICScAABCwgkAICScAABCwgkAICScAABCwgkAICScAABCwgkAICScAABCwgkAICScAABCs3ZE+r5vY3flypXSvTt37rRqXde1Mbt8+XL55tbWVunem2++2apNJpNRf86Hcd1Uf6fHfm0fhsViUbo3m9Xf4v/zn/+U7j399NOjv26qv8+3b99u1S5dulS+yVvzxAkAICScAABCwgkAICScAABCwgkAICScAABCwgkAICScAABCwgkAICScAABCwgkAICScAABCwgkAICScAABCwgkAICScAABCwgkAICScAABCwgkAICScAABCs3aMPPjgg23Mdnd3yzdPnz5durdYLEr33vOe97RqN2/eLN3b399v1WazY/XVOhJd14167zA2q/em02mrdvv27dK9p556qo3dwcHBqPfu2dnZKd177LHHSvc2NzfbceGJEwBASDgBAISEEwBASDgBAISEEwBASDgBAISEEwBASDgBAISEEwBASDgBAISEEwBASDgBAISEEwBASDgBAISEEwBASDgBAISEEwBASDgBAISEEwBAaNaOkStXrpTunTt3rnTv5s2brdr+/n7pXtd1pXt7e3tt7K95aWmpVRuGoXRvPp+X7vV9306a6mv7pJ5j9fev+rtyGE6dOlW6d/fu3Vbt/PnzpXvPPfdc6d6LL77YjgtPnAAAQsIJACAknAAAQsIJACAknAAAQsIJACAknAAAQsIJACAknAAAQsIJACAknAAAQsIJACAknAAAQsIJACAknAAAQsIJACAknAAAQsIJACAknAAAQrN2jHzzm98s3dvd3S3dm8/nrdrS0tKoz7H6/O7Z2Ngo3VtfX2/Vbty4UbrX933pXtd1beyGYRj9a64+x+l0Ouq9e5aXl0v3rl27Vrq3WCxatclk/M8YDg4OSveef/750r0XX3yxHRfjvxoAAEZCOAEAhIQTAEBIOAEAhIQTAEBIOAEAhIQTAEBIOAEAhIQTAEBIOAEAhIQTAEBIOAEAhIQTAEBIOAEAhIQTAEBIOAEAhIQTAEBIOAEAhIQTAEBIOAEAhGbtGFlfXy/du337dune8vJyq3ZwcFC6t7e3V7o3m9VfYi+99FLp3tLSUqu2s7NTunfjxo1Rf86HdX1XWiwWo9+s/j6vrq62ao8//njp3sc//vFRv4eH8X2ZTOqfWVS/7k9/+tOle8eJJ04AACHhBAAQEk4AACHhBAAQEk4AACHhBAAQEk4AACHhBAAQEk4AACHhBAAQEk4AACHhBAAQEk4AACHhBAAQEk4AACHhBAAQEk4AACHhBAAQEk4AAKFZOyK///3vyzcfeuih0r2tra02drNZ7UfYdV3p3t27d1u1559/vnwTOBo/+clPSve+/vWvt2p937exu3Pnzqh/W55++ulW7c9//nM7Cp44AQCEhBMAQEg4AQCEhBMAQEg4AQCEhBMAQEg4AQCEhBMAQEg4AQCEhBMAQEg4AQCEhBMAQEg4AQCEhBMAQEg4AQCEhBMAQEg4AQCEhBMAQEg4AQCEhBMAQGjWjsgPfvCD8s2f/exnpXsbGxulezdv3mzV9vb22pjt7++3k2g6nbYx67pu9JvDMIx67zBUv4eH8TkfHByU7q2urpbu7e7utrG/5smk/pnFAw88MOp72Pe///1W7cqVK+0oeOIEABASTgAAIeEEABASTgAAIeEEABASTgAAIeEEABASTgAAIeEEABASTgAAIeEEABASTgAAIeEEABASTgAAIeEEABASTgAAIeEEABASTgAAIeEEABCatSPy29/+tnzz/e9/f+ne9773vdK9F154oVU7ODgo3fvXv/5Vure5udlOor7vS/eGYSjdg7FYWloq3VtZWWnVLly4ULr373//u1X7xz/+Ubr3ne98p3TvN7/5TTsuPHECAAgJJwCAkHACAAgJJwCAkHACAAgJJwCAkHACAAgJJwCAkHACAAgJJwCAkHACAAgJJwCAkHACAAgJJwCAkHACAAgJJwCAkHACAAgJJwCAkHACAAh1wzAM73TQzs5OW1tbSzcBGIHZbFa+OZ/PS/cuX75cuvfUU0+1ar/73e9K9/72t7+V7lFne3u7ra6uvu0xnjgBAISEEwBASDgBAISEEwBASDgBAISEEwBASDgBAISEEwBASDgBAISEEwBASDgBAISEEwBASDgBAISEEwBASDgBAISEEwBASDgBAISEEwBASDgBAISEEwBAqBuGYXing3Z2dtra2lobu8mktgODt+ZI906qrutK93wuAP/dbDYr3ZvP5+1+sL293VZXV9/2GE+cAABCwgkAICScAABCwgkAICScAABCwgkAICScAABCwgkAICScAABCwgkAICScAABCwgkAICScAABCwgkAICScAABCwgkAICScAABCwgkAIDRLDhqGod0Pqs/zfnndJ43PBeBwndT77BC87iicbt261e4HJ/WDBoBKi8WinUS3bt1qa2trb3tMNwS10fd9e/3119v58+db13WV5wgAcKTupdC9aHr00UfbZDJ59+EEAIB/ORwAICacAABCwgkAICScAABCwgkAICScAABCwgkAoGX+C35ObDbRcz6qAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1400x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "example_shirt = 0\n",
    "visualize_images(X_train[example_shirt])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1724e9e-627a-4b56-ac48-15ac73c4d8fd",
   "metadata": {},
   "source": [
    "# (25 points) computing adversarial examples\n",
    "\n",
    "We now would like to verify the robustness of our classifier by looking at adversarial examples. To do so, we will consider all images close to a *representative image* and see if appropriate pixel perturbations could confuse our classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7fb159-33e9-4e0d-99a7-976c2722cf9a",
   "metadata": {},
   "source": [
    "1. (10 points) Formulate the problem of finding the closest image, in terms of the $\\ell_1$-norm, to the shirt one at index `example_shirt = 0`, that gets misclassified.\n",
    "\n",
    "    Note: images have pixel intensities between 0 and 255."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6706d47",
   "metadata": {},
   "source": [
    "1. $$ \\begin{array}{ll@{}l}\n",
    "\\min\\limits_{x} & \\|x - x_{\\text{orig}}\\|_1 = \\sum_{j=1}^m |x_j - x_{\\text{example},j}| & \\\\\n",
    "\\text{s.t.} & a^T x + b \\leq 0 & \\text{(Misclassification constraint)} \\\\\n",
    "& 0 \\leq x_j \\leq 255, & \\forall j = 1, \\dots, m \\text{ (Pixel bounds)}\n",
    "\\end{array} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c62e7f5-adf3-4dbd-9544-9b4d4ae29b2e",
   "metadata": {},
   "source": [
    "2. (5 points) Formulate the problem as a linear program in inequality form without including any norm.\n",
    "$$ \\begin{array}{ll}\n",
    "\\text{maximize} & \\sum_i t_i \\\\\n",
    "\\text{subject to } & a^Tx + b \\leq 0 \\\\\n",
    "& t_j \\geq x_j - x_{example, j} \\quad \\forall j \\\\\n",
    "& t_j \\geq x_{example, j} - x_j \\quad \\forall j \\\\\n",
    "& 0 \\leq x_j \\leq 255 \\forall j \\\\\n",
    "& t_j \\geq 0 forall j\n",
    "\\end{array} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf0f06a-ef5e-49e0-8e24-6ab2062f3a7b",
   "metadata": {},
   "source": [
    "3. (10 points) Solve problem compare the resulting image with the example shirt above. How many pixels are modified? What is the $\\ell_1$-norm distance between the images? Plot the images side by side using the `visualize_images` function above and describe what's different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "053f50d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_misclassified_lp(x_example, a, b):\n",
    "    \"\"\"\n",
    "    Finds the closest misclassified image to x_example via LP formulation.\n",
    "    \n",
    "    Parameters:\n",
    "        x_example : np.ndarray (original image, shape [m,])\n",
    "        a         : np.ndarray (SVM weights, shape [m,])\n",
    "        b         : float      (SVM bias)\n",
    "        epsilon   : float      (small positive value for strict inequality)\n",
    "    \n",
    "    Returns:\n",
    "        x_adv : np.ndarray (adversarial image)\n",
    "    \"\"\"\n",
    "    m = len(x_example)\n",
    "    x = cp.Variable(m)\n",
    "    t = cp.Variable(m)  # Auxiliary variables for |x_j - x_example,j|\n",
    "    \n",
    "    objective = cp.Minimize(cp.sum(t))\n",
    "    constraints = [\n",
    "        a.T @ x + b <= 0,           # Misclassification\n",
    "        x - x_example <= t,                 # t_j ≥ x_j - x_example,j\n",
    "        x_example - x <= t,                 # t_j ≥ x_example,j - x_j\n",
    "        0 <= x, x <= 255,                   # Pixel bounds\n",
    "        t >= 0                              # t_j ≥ 0\n",
    "    ]\n",
    "    \n",
    "    problem = cp.Problem(objective, constraints)\n",
    "    problem.solve(solver=cp.CLARABEL)\n",
    "    \n",
    "    if problem.status not in [cp.OPTIMAL, cp.OPTIMAL_INACCURATE]:\n",
    "        raise ValueError(f\"Optimization failed with status: {problem.status}\")\n",
    "    \n",
    "    return x.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f7fc0c1c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "np.int64(5)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m best_lambda = np.argmin(errors) \n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m a = \u001b[43msvms\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbest_lambda\u001b[49m\u001b[43m]\u001b[49m.a\n\u001b[32m      3\u001b[39m b = svms[best_lambda].b\n\u001b[32m      4\u001b[39m adv_example = find_misclassified_lp(X_train[example_shirt], a, b)\n",
      "\u001b[31mKeyError\u001b[39m: np.int64(5)"
     ]
    }
   ],
   "source": [
    "best_lambda = np.argmin() \n",
    "a = svms[best_lambda].a\n",
    "b = svms[best_lambda].b\n",
    "adv_example = find_misclassified_lp(X_train[example_shirt], a, b)\n",
    "\n",
    "visualize_images(X_train[example_shirt], adv_example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "70fbe170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(784)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(adv_example != X_train[example_shirt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf451ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
