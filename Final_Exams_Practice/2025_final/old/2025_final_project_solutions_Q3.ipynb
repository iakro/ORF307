{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4baf963",
   "metadata": {},
   "source": [
    "# 2025 Spring ORF307 Final Project Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2420c4d",
   "metadata": {},
   "source": [
    "Instructor: B. Stellato\n",
    "\n",
    "AIs: Yanjun Liu, Qishuo Yin, Chenyu Yu, and Kaiwen Zhang\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac556b07",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "**Exam files:** the exam files are available to download at [THIS LINK.](https://www.dropbox.com/scl/fo/b6an98pypucpvdhb81osz/AHSPIHMuLOtnttr-CDG6ZZY?rlkey=6wph0csyr9gldp2lo7akkx4ln&st=ckxp1xua&dl=0)\n",
    "\n",
    "**Date and time:** From May 8, 2025 at 00:01 am to May 11, 2025 at 7:00pm.\n",
    "\n",
    "- Total time after download: 24 hours. No late submissions allowed. Note that the deadline is either 24 hours after download, or May 11, 2025 at 7:00pm, **whichever comes first**.\n",
    "\n",
    "## Exam Rules\n",
    "- You are allowed to use all course materials on the midterm (lecture notes, books, precept materials, code, and homeworks). But you cannot use internet to search for answers.\n",
    "- You have to justify all your answers. If you use code from the course materials, you have to explain what each step means.\n",
    "- You cannot communicate with anyone during the exam.\n",
    "- No late submissions allowed. Make sure your submission goes through on time. You can resubmit as many times as you like until your time expires.\n",
    "- The exam is to be submitted electronically on Gradescope before 7:00pm on the final day."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34ddc29",
   "metadata": {},
   "source": [
    "# Final Exam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dde275a-2a25-4947-a756-8ac4c91cf33b",
   "metadata": {},
   "source": [
    "## Introduction \n",
    "\n",
    "For this final project, you will work with the Fashion MNIST dataset including thousands of images of clothes, which we have provided in CSV format. \n",
    "\n",
    "You will work with a pre-processed version of this dataset where each label is +1 if the image is a shirt and -1 otherwise.\n",
    "\n",
    "To load the dataset, ensure the following files are in a folder called `data/` in your working directory: `X_train.csv`, `y_train.csv`, `X_test.csv`, `y_test.csv`. Then run the following code to import the packages and load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d769c1d-b92e-4bd9-9813-ca9dedd37f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(precision=4)  # Print few decimal places\n",
    "np.set_printoptions(suppress=True)  # Suppress scientific notation\n",
    "import cvxpy as cp\n",
    "import pandas as pd\n",
    "from numpy.linalg import cholesky as llt\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c304ea7b-76c2-48ff-8498-c024e4ad5e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Fashion MNIST dataset\n",
      "--------------------------------------------------\n",
      "Number of features: 784  (28 x 28 pixels)\n",
      "Training set:\n",
      "  • Samples: 5000\n",
      "  • Value range: [0.00, 255.00]\n",
      "Test set:\n",
      "  • Samples: 1000\n",
      "  • Value range: [0.00, 255.00]\n"
     ]
    }
   ],
   "source": [
    "X_train = pd.read_csv(f\"data/X_train.csv\").values\n",
    "y_train = pd.read_csv(f\"data/y_train.csv\").values.ravel()\n",
    "X_test = pd.read_csv(f\"data/X_test.csv\").values\n",
    "y_test = pd.read_csv(f\"data/y_test.csv\").values.ravel()\n",
    "\n",
    "n_train, m = X_train.shape\n",
    "n_test, m = X_test.shape\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(\"Fashion MNIST dataset\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Number of features: {m}  ({int(np.sqrt(m))} x {int(np.sqrt(m))} pixels)\")\n",
    "print(f\"Training set:\")\n",
    "print(f\"  • Samples: {n_train}\")\n",
    "print(f\"  • Value range: [{X_train.min():.2f}, {X_train.max():.2f}]\")\n",
    "print(f\"Test set:\")\n",
    "print(f\"  • Samples: {n_test}\")\n",
    "print(f\"  • Value range: [{X_train.min():.2f}, {X_train.max():.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127658a5-975f-44e9-ab95-79ba834ff61f",
   "metadata": {},
   "source": [
    "Now, let's visualize a couple of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7028a681-fefc-48ee-ad05-7aaca525058a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_images(*images):\n",
    "    n_images = len(images)\n",
    "    fig, axes = plt.subplots(1, n_images, figsize=(14,6))\n",
    "    if n_images == 1:\n",
    "        axes = [axes]   \n",
    "    for i, (ax, img) in enumerate(zip(axes, images)):\n",
    "        img_reshaped = img.reshape(28, 28)\n",
    "        im = ax.imshow(img_reshaped, cmap='gray')\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e33c88ae-e1ad-4931-82ec-ab51436c7904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "example_boot = X_train[3]\n",
    "example_shirt = X_train[0]\n",
    "visualize_images(example_boot, example_shirt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ea2986-d059-4c87-97f0-d0686d1a5d12",
   "metadata": {},
   "source": [
    "# 1. (35 points) Build a Support Vector Machine to correctly classify shirts\n",
    "\n",
    "1. (5 points) Formulate a Support Vector Machine problem to find a hyperplane $(a, b)$ where $a \\in \\mathbf{R}^m$ and $b \\in \\mathbf{R}$ to classify shirts. Given sample $x^{(i)}$, your hyperplane should be $a^Tx^{(i)} + b > 0$ if label $y^{(i)} = 1$ (shirt) or $a^Tx^{(i)} + b < 0$ if label $y^{(i)} = -1$ (not a shirt). You should include a second term in the objective, weighted by parameters $\\lambda > 0$ to regularize the $\\ell_1$-norm of $a$.\n",
    "\n",
    "    Note: Remember to normalize the misclassification error by the total number of training samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa09013-6958-4308-9bf9-af577b7b7470",
   "metadata": {},
   "source": [
    "2. (7 points) Run a cross-validation procedure: solve the problem using CVXPY and CLARABEL solver for $\\lambda = (0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05)$ and pick the model that has the lowest test error.\n",
    "\n",
    "    Note, these problems are quite large so it may take a few seconds to solve them. (you may use the argument `verbose=True` to print out the solver progress).\n",
    "\n",
    "    Here is a utility function to check the test error. For example, you can use it as `error(X_test, y_test, a, b)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "46880e87-e38f-4b64-a1f9-ea4fd21b6534",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(X, y, a, b):\n",
    "    y_pred = np.sign(X @ a + b)\n",
    "    return np.mean(y_pred != y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35900140-4d89-45b2-b245-e976871d5ddc",
   "metadata": {},
   "source": [
    "3. (7 points) Write the training problem as a linear program in inequality form (get rid of all norms in the formulation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c244b64-5989-49a4-8655-1d5745a15156",
   "metadata": {},
   "source": [
    "4. (7 points) Write the dual problem and call the dual variables corresponding to the misclassified points as $z \\in \\mathbf{R}^{\\rm n\\_train}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416e371d-9ef3-476f-95fe-6f05ec872289",
   "metadata": {},
   "source": [
    "5. (7 points) Identify which points are misclassified using the dual variables $z$. Visualize the images corresponding to the 5 largest dual variables. How do they compare to a shirt image below?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6631db87-fa13-4e4b-a39a-9e4913f28930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGbCAYAAAAr/4yjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAATeElEQVR4nO3dXWyWd/0G8G9faPvQFqhbq1YZIMhYhnMGD3BmsjgPjJodLpnJMvVANCYmejBNtoivicRMTxaz6YFLOJIly/RsiQGj7kgx6rJIUCyKoI4y+iJ97/P8D4xfx3+D9ffb9lDo55Ms2drn4r57P0+5etNyraPVarUCACKi82qfAACrh1IAICkFAJJSACApBQCSUgAgKQUAklIAICkFAJJSYNV54oknoqOjI06dOlWcveuuu2L37t2v6/ls3bo1PvGJT7yuvyasVkoB3mDf+ta34p577ok3v/nN0dHREV/96lev9inBZSkFeIM9/PDD8etf/zre8573XO1TgVfVfbVPAK53Y2NjsXXr1hgfH4/h4eGrfTpwRe4UuCb85Cc/iY9+9KMxOjoavb29sX379vjGN74Ry8vLr/j4Y8eOxR133BGNRiO2bdsWjz322MseMz8/HwcOHIgdO3ZEb29vbN68OR588MGYn59/1fM5efJknDx5ckXnvnXr1hU9DlYDdwpcE5544okYGBiIL37xizEwMBBHjhyJr3zlKzE1NRXf+c53LnnshQsX4iMf+Ujce++9cd9998Xhw4fjs5/9bPT09MSnPvWpiIhoNptxzz33xK9+9av49Kc/Hbfccks899xz8b3vfS9OnDgRTz/99BXP5+67746IqPpmOKxqLVhlfvSjH7UiojU2NpZvm5mZednj9u/f31q/fn1rbm4u37Zv375WRLQeeeSRfNv8/Hzr9ttvb42MjLQWFhZarVardejQoVZnZ2frl7/85SW/5mOPPdaKiNazzz6bb9uyZUvrgQceuORxW7ZsaW3ZsqXo4zp37lwrIloHDhwoykE7+eMjrgmNRiP/fXp6OsbHx+POO++MmZmZOH78+CWP7e7ujv379+d/9/T0xP79++OFF16IY8eORUTEk08+Gbfcckvs2rUrxsfH858PfvCDERFx9OjRK57PqVOn3CVwXfLHR1wTnn/++Xj44YfjyJEjMTU1dcn7JicnL/nv0dHR6O/vv+RtO3fujIj//Ga+d+/e+NOf/hR//OMfL/uN3xdeeOF1PHu4digFVr2JiYnYt29fbNiwIb7+9a/H9u3bo6+vL37729/Gl770pWg2m8W/ZrPZjHe9613x3e9+9xXfv3nz5td62nBNUgqsej//+c/j/Pnz8dRTT8UHPvCBfPvY2NgrPv7s2bNx8eLFS+4WTpw4ERH/+0mg7du3x+9///u4++67o6Oj4407ebjG+J4Cq15XV1dERLRarXzbwsJCfP/733/Fxy8tLcXjjz9+yWMff/zxGB4ejj179kRExL333htnzpyJH/7why/Lz87OxsWLF694TiU/kgrXEncKrHp33HFHDA0NxQMPPBCf//zno6OjIw4dOnRJSbzU6OhoHDx4ME6dOhU7d+6MH//4x/G73/0ufvCDH8S6desiIuL++++Pw4cPx2c+85k4evRovP/974/l5eU4fvx4HD58OJ555pl473vfe9lzKvmR1EOHDsVf//rXmJmZiYiIX/ziF/HNb34zz2PLli0llwPeWFf7x5/g/3ulH0l99tlnW3v37m01Go3W6Oho68EHH2w988wzrYhoHT16NB+3b9++1q233tr6zW9+03rf+97X6uvra23ZsqX16KOPvuw4CwsLrYMHD7ZuvfXWVm9vb2toaKi1Z8+e1te+9rXW5ORkPu61/kjqf39M9pX+eem5w2rQ0Wpd5sstANYc31MAICkFAJJSACApBQCSUgAgrejvKTSbzTh79mwMDg76258A16BWqxXT09MxOjoanZ2Xvx9YUSmcPXvWFgzAdeD06dPx9re//bLvX1EpDA4Ovm4nxNr10jnrEv9/BXUllpaWijP//RvHJXbt2lWcefHFF4szEf/5Hw3Ba/Vqv5+vqBT8kdG1o+a5atffX+zt7a3K9fT0FGdqrsN/JzBK1HxMNR9PO63m1xCv3as9v77RDEBSCgAkpQBAUgoAJKUAQFIKACSlAEBSCgAkpQBAUgoApBX9P5qnpqZi48aN7Tif61J394rWRC5Rs93TTjt27CjOHD16tOpYJ06cKM60a0ri4sWLxZlt27ZVHatmZ2k1z09caanzSprN5ut8JmvL5ORkbNiw4bLvd6cAQFIKACSlAEBSCgAkpQBAUgoAJKUAQFIKACSlAEBSCgAkpQBAUgoAJIN4hTo6Oooz7Rwlqxnf+9jHPlac+eQnP1mc+fe//12ciYgYGRkpzkxOThZnent7izPj4+PFmVqzs7PFmUceeaQ4c/LkyeJMO632z8HVziAeACumFABISgGApBQASEoBgKQUAEhKAYCkFABISgGApBQASEoBgKQUAEhKAYBkJbUNdu/eXZz5+Mc/XnWsvXv3FmdqFiT/+c9/FmdefPHF4kxExNLSUnGmp6enODM3N1ecqbFp06aq3MDAQHHmLW95S3Hm/PnzxZkjR44UZx599NHiTC3Lqv9jJRWAFVMKACSlAEBSCgAkpQBAUgoAJKUAQFIKACSlAEBSCgAkpQBAUgoAJIN4hXbs2FGcOXjwYHFmYWGhOBMRMTMzU5ypGZyrOb+RkZHiTETE0NBQcWZxcbE4Mzs7W5ypuQ5TU1PFmYiIzs7yr+FqRt36+vqKMzUjf3/5y1+KMxERX/jCF6py/IdBPABWTCkAkJQCAEkpAJCUAgBJKQCQlAIASSkAkJQCAEkpAJCUAgBJKQCQuq/2CVxr7rvvvuJMzeDcxMREcSYiotFoFGdqxuNqhtbOnz9fnImIuHDhQnGm5mNat25dcabmOtS8HiIiurq6ijM1I3o151fz3L7pTW8qzkREdHR0FGdqnqe1yp0CAEkpAJCUAgBJKQCQlAIASSkAkJQCAEkpAJCUAgBJKQCQlAIASSkAkAziFbr99tuLM/Pz88WZmvGzWjXjcTWjZMvLy8WZ2mPVXL+a0bS5ubniTO1zW3v92nGc3t7e4kx/f39xJiLi5ptvLs4cP3686lhrkTsFAJJSACApBQCSUgAgKQUAklIAICkFAJJSACApBQCSUgAgKQUAklIAIBnEK7Rp06bizL/+9a/X/0QuY2ZmpjhTM4jX3V3+0qnJXI9qB/FqnqcaNcOAjUajOLNu3briTETEbbfdVpwxiLdy7hQASEoBgKQUAEhKAYCkFABISgGApBQASEoBgKQUAEhKAYCkFABISgGApBQASGt6tnJwcLA4U7P02dlZ3r09PT3FmYiIZrPZlkzNYmdHR0dxJqLu/GqOVbNeWrMourS0VJyJiFhYWCjO1CyR1rzGBwYGijM1z2tExM0331yVY2XcKQCQlAIASSkAkJQCAEkpAJCUAgBJKQCQlAIASSkAkJQCAEkpAJCUAgBpTQ/i3XTTTcWZ9evXF2dqhr9qjhMRceHCheLM/Px8cabm/JaXl4szEXWjczWjbu0a3qsZSKw1OztbnBkeHi7ONBqN4szk5GRxJqLu/Fg5dwoAJKUAQFIKACSlAEBSCgAkpQBAUgoAJKUAQFIKACSlAEBSCgAkpQBAWtODeENDQ8WZmjGziYmJ4sw73vGO4kxExOnTp4szXV1dVcdazZaWloozNc9tzSBe7TBgX19fceYf//hHcWbv3r3FmZpRxZqhw4iIkZGRqhwr404BgKQUAEhKAYCkFABISgGApBQASEoBgKQUAEhKAYCkFABISgGApBQASGt6EG94eLgtx6kZZ2s2m1XH2rVrV3Fmbm6uOPPnP/+5OFMz6BZRNzpXo2YQr+Z5qh3Eq7kO69evL87UfF6MjY0VZ2r19/e37VhrkTsFAJJSACApBQCSUgAgKQUAklIAICkFAJJSACApBQCSUgAgKQUAklIAICkFANKaXkkdGBgoziwuLhZn2rmkuXv37uLMH/7wh+LMwsJCcabRaBRnIiJarVZxpmbxtF1qV19rXkeDg4PFmZpr193dvt9Kent723astWj1fuYA0HZKAYCkFABISgGApBQASEoBgKQUAEhKAYCkFABISgGApBQASEoBgLSmB/F6enqKMzVDdTUDY7WjXzXn97e//a0409XVVZypVTMgt7S0VJypGd6rObeaYbvaY9Vk1q1bV5yp+VyqHS1s52tvLXKnAEBSCgAkpQBAUgoAJKUAQFIKACSlAEBSCgAkpQBAUgoAJKUAQFIKAKQ1PYhXM5pWM2ZWM25XO/q1ffv24sz4+Hhx5sYbbyzOLC4uFmci6gbaatSMx7VrRK/2WPPz88WZbdu2FWfOnj1bnKm9Dgbx3ljuFABISgGApBQASEoBgKQUAEhKAYCkFABISgGApBQASEoBgKQUAEhKAYC0pgfx2qW7u/wyb9q0qepYTz31VHFmaGioOFMzUlczzhYR0dlZ/rVLTaZmcK6daq751NRUcebJJ58szmzdurU4U6vmuWXlXF0AklIAICkFAJJSACApBQCSUgAgKQUAklIAICkFAJJSACApBQCSUgAgGcRrgxtuuKE4MzY2VnWsb3/728WZAwcOFGdOnTpVnKm1vLxcnGnXuF3NudUMJEbUDQqOjIwUZ55++unizEMPPVScqR22azabVTlWxp0CAEkpAJCUAgBJKQCQlAIASSkAkJQCAEkpAJCUAgBJKQCQlAIASSkAkJQCAGlNr6Q2Go3izPnz54szQ0NDxZmf/exnxZmIiMHBweJMb29vcaZdK6S1Ojo62pKpXTytsbS0VJypeW67urqKM7Ozs8WZmusdEXHx4sXiTE9PT3FmYWGhOHM9cKcAQFIKACSlAEBSCgAkpQBAUgoAJKUAQFIKACSlAEBSCgAkpQBAUgoApDU9iPfOd76zODM9PV2cedvb3lacmZiYKM5EROzZs6c4UzMwVjME186BseXl5eJMZ+fq/hqp5prXDBfWjMedO3euOFOr5vxW+3O7mrhSACSlAEBSCgAkpQBAUgoAJKUAQFIKACSlAEBSCgAkpQBAUgoAJKUAQFrTg3j9/f3FmZmZmeJMzRjXDTfcUJyJiOjq6irOzM3NFWc6OjqKM0tLS8WZiLoBtBrNZrM4UzM4V3PtanM1w4Dr168vzszOzhZnakfqaj6m4eHh4szp06eLM9cDdwoAJKUAQFIKACSlAEBSCgAkpQBAUgoAJKUAQFIKACSlAEBSCgAkpQBAWtODeDXDWr29vcWZCxcuFGf6+vqKMxF1I2MLCwvFmZpxttoBtJpjbdy4sThTM3a4uLhYnKkZLYyoG9+rOb+a1978/HxbjhMRce7cueLMhg0bqo61FrlTACApBQCSUgAgKQUAklIAICkFAJJSACApBQCSUgAgKQUAklIAICkFANKaHsSrGclqNBrFmeHh4eLMjTfeWJyJiJidnS3O1Ayt1YzU1Ryn1tzcXHGmZiCxncOANcOFNaNz/f39xZk777yzOPPcc88VZyLqPqbbbrutOPP8888XZ64H7hQASEoBgKQUAEhKAYCkFABISgGApBQASEoBgKQUAEhKAYCkFABISgGApBQASGt6JfVzn/tcceauu+4qztSsLW7evLk4ExHx5S9/uTgzNjZWnKlZB202m8WZiLp11ZpjtWv5tZ3XoaurqzgzMDBQnPnwhz/cluNE1C3gnjlzpupYa5E7BQCSUgAgKQUAklIAICkFAJJSACApBQCSUgAgKQUAklIAICkFAJJSACCt6UG8qamp4sxPf/rTN+BMXu5DH/pQVa5mNG1xcbE409PTU5ypGZyrzfX29hZn5ufnizPd3e37FFpeXi7O1IzH7dy5szhz/Pjx4gyrkzsFAJJSACApBQCSUgAgKQUAklIAICkFAJJSACApBQCSUgAgKQUAklIAIK3pQbzOzvJOrBmcq8m8+93vLs5ERIyPjxdnasbjasftatQ8TzXnVzNuV3OcZrNZnImIWLduXVuONTExUZzZs2dPcebYsWPFmYi661AzJlj7PF3r3CkAkJQCAEkpAJCUAgBJKQCQlAIASSkAkJQCAEkpAJCUAgBJKQCQlAIAaU0P4tUMXnV1dRVnasa4atWMui0tLRVnaq7d5ORkcSaibnSu0WgUZ+bm5oozNWN9tUNrNa+9GgMDA8WZmpG6WjUDk2t13K6GOwUAklIAICkFAJJSACApBQCSUgAgKQUAklIAICkFAJJSACApBQCSUgAgKQUAUkdrBZODU1NTsXHjxnacz6rXrpXUnTt3FmciIh566KHiTF9fX3HmrW99a3FmYWGhOBNRt0Rak6l5nmoWXGudOXOmOFOzXrq4uFicuf/++4sztWquec2y6vVqcnIyNmzYcNn3u1MAICkFAJJSACApBQCSUgAgKQUAklIAICkFAJJSACApBQCSUgAgKQUAkkE84qabbirOjI6OFmdqhvdqNRqN4kx3d3dxpmacrXYYcGJiojhz8uTJ4sy5c+eKMzVqRgsjIprN5ut8JmuLQTwAVkwpAJCUAgBJKQCQlAIASSkAkJQCAEkpAJCUAgBJKQCQlAIAaUVjLyuYR+IaVrMls7S01JZMrcXFxeJMzeu8Zvuo9jrU5FbzTpDfV66OV7vuKyqF6enp1+VkWJ3+/ve/tyUDL6UUro7p6ekrDpyuaCW12WzG2bNnY3BwsOorIwCurlarFdPT0zE6OnrFhdoVlQIAa4NvNAOQlAIASSkAkJQCAEkpAJCUAgBJKQCQ/g9GnfYmbV09rgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "example_shirt = 0\n",
    "visualize_image(X_train, example_shirt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1724e9e-627a-4b56-ac48-15ac73c4d8fd",
   "metadata": {},
   "source": [
    "# (25 points) computing adversarial examples\n",
    "\n",
    "We now would like to verify the robustness of our classifier by looking at adversarial examples. To do so, we will consider all images close to a *representative image* and see if appropriate pixel perturbations could confuse our classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7fb159-33e9-4e0d-99a7-976c2722cf9a",
   "metadata": {},
   "source": [
    "1. (10 points) Formulate the problem of finding the closest image, in terms of the $\\ell_1$-norm, to the shirt one at index `example_shirt = 0`, that gets misclassified.\n",
    "\n",
    "    Note: images have pixel intensities between 0 and 255."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c62e7f5-adf3-4dbd-9544-9b4d4ae29b2e",
   "metadata": {},
   "source": [
    "2. (5 points) Formulate the problem as a linear program in inequality form without including any norm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf0f06a-ef5e-49e0-8e24-6ab2062f3a7b",
   "metadata": {},
   "source": [
    "3. (10 points) Solve problem compare the resulting image with the example shirt above. How many pixels are modified? What is the $\\ell_1$-norm distance between the images? Plot the images side by side using the `visualize_images` function above and describe what's different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a058363b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Obtain SVM shirt classifier\n",
    "### Build based on from Chenyu's solution to Q1\n",
    "class SVM:\n",
    "    def __init__(self, lambda_val):\n",
    "        \"\"\"\n",
    "        Initialize SVM with L1 regularization parameter.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        lambda_val : float\n",
    "            Regularization param >=0 .\n",
    "        \"\"\"\n",
    "        if lambda_val < 0:\n",
    "            raise ValueError(\"lambda_val must be non-negative.\")\n",
    "        self.lambda_val = lambda_val\n",
    "        self.a = None\n",
    "        self.b = None\n",
    "\n",
    "    def fit(self, X, y, solver=cp.CLARABEL):\n",
    "        \"\"\"\n",
    "        Fit the SVM model to the training data using convex optimization.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : np.ndarray, shape (n_samples, n_pix)\n",
    "            Training feature matrix.\n",
    "        y : np.ndarray, shape (n_samples,)\n",
    "            Training labels (±1).\n",
    "        solver : cvxpy solver, optional\n",
    "            Solver to use (default: CLARABEL).\n",
    "        verbose : bool, optional\n",
    "            Whether to print solver progress (default: False).\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        a : np.ndarray\n",
    "            Learned weight vector.\n",
    "        b : float\n",
    "            Learned bias term.\n",
    "        \"\"\"\n",
    "        n_samples, n_pix = X.shape\n",
    "        a = cp.Variable(n_pix)\n",
    "        b = cp.Variable()\n",
    "        \n",
    "        hinge_loss = cp.sum(cp.pos(1 - cp.multiply(y, X @ a + b))) / n_samples\n",
    "        objective = cp.Minimize(hinge_loss + self.lambda_val * cp.norm(a, 1))\n",
    "\n",
    "        problem = cp.Problem(objective)\n",
    "        problem.solve(solver=solver)\n",
    "        \n",
    "        self.a = a.value\n",
    "        self.b = b.value\n",
    "        \n",
    "        return self.a, self.b\n",
    "\n",
    "lambda_val = 0.1\n",
    "svm = SVM(lambda_val)\n",
    "a, b = svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44331789-ee63-4798-b2ba-9a80cdde5b7b",
   "metadata": {},
   "source": [
    "# 3 (35 points) Production plannin with quality control via SVM\n",
    "You are a clothing manufacturer that produces a certain amount of shirts (`n_shirts`) daily but can only inpsect 40% of them due to resource constraints. Your excellent shirt classifier from part 1 wil turn out to be helpful to decide which ones to inspect. The company incurs in various costs:\n",
    "\n",
    "- Inspection cost: $c = 10$ per item inspected\n",
    "- False negative (error) cost: $d = 20$ per defective item that reaches a customer (which will not be happy about the purchase)\n",
    "- True positive (correct) cost (savings): $s = 15$ from catching a defective item before shipping\n",
    "\n",
    "For each shirt $i$, you need to decide whether to inspect it using binary variable $w_i \\in \\{0, 1\\}$. We will use the trained SVM problem to suggest to inspect the item if it is not classified as a shirt. Specifically, we transform the output of the SVM into a probability with values between $0$ and $1$ using the following function. For an image $i$, the probability of the product to be defective (i.e., not a shirt) is \n",
    "$$p^{(i)} = \\sigma(- (a^Tx^{(i)} + b)),$$\n",
    "where $\\sigma(x) = 1 / (1 + \\exp(-x))$ is the sigmoid function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2915e2e",
   "metadata": {},
   "source": [
    "1. (5 points) Calculate the predicted probabilities for all training shirt images. Use the `X_shirt_train` images data defined here for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b4cf42d-cb54-45e2-b762-bf5170bdad63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2836 0.2689 0.0598 ... 0.7721 0.1018 0.2318]\n"
     ]
    }
   ],
   "source": [
    "# get shirt images from training first\n",
    "shirt_indices_train = np.where(y_train == 1)[0]\n",
    "X_shirt_train = X_train[shirt_indices_train]\n",
    "n_shirt_train = X_shirt_train.shape[0]\n",
    "inspection_capacity_train = int(0.4 * n_shirt_train)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def prob(X, a, b):\n",
    "    return sigmoid(- (X @ a + b))\n",
    "\n",
    "prob_train = prob(X_shirt_train, a, b)\n",
    "print(prob_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66eb8729-6227-4bc3-9c6f-175a45eb4465",
   "metadata": {},
   "source": [
    "2. (5 points) Run naive approach. Inspect items with larger probability of being defective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e239c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1040 1489  232 2040  777 1573 1131  619 1855  959 2331 1935 2468 1465\n",
      " 2462  887 1703  650  870 1065  654 1309  707  799 1448 2335  778 2062\n",
      " 1412 1977 1760 1113 1033 1248 1689  392 1269 2298 1627  465 1660 1147\n",
      " 1114 1900 2090  695  285  160  307 1241 1985  479 1517 1092 1121 1249\n",
      " 1122 1716 2186 1452  889  585 2470 2314  945  140  457 1074 1853 2491\n",
      "  826  449 1110   76  602 1630 1858 1677 1800  241 2047 2081  192 1529\n",
      "   16 1173 2217 2195 1998 1680  420 1780 1847  704   17 2324   68 2293\n",
      "  338 1511 2494 1409 1606 1812 1862 1766  744 1111 1765 1928 1662 2496\n",
      "  868 2236  828   32 2429  515 1082  682  974  867  118 1424  330 1701\n",
      " 1398  220  313  262 1658  177 1509 2213  816  541 1302 2437 2205 2345\n",
      "  784 1651 1727 1740  497  399  858  374 1387 2064  265 1590 1585 1892\n",
      " 1470 2489 2312  450 2276  348  676 1714  643 1072  708 1174 1239  259\n",
      " 1969  434 2364  303 1372 1650  344  369 2181 1789  427 2097 2067 2112\n",
      "  806  151 1077  866 1413 2384  814  416  254 1804  940  752 2209 2001\n",
      " 2156  494 2011  309 1244 2469 1635 2174  580  581 1795 1494  616 1881\n",
      "  832 2250 1681 2294 1637 2305 1907  726 2246 1768 1061 1817 2091  332\n",
      " 1418 2029  967  152    1   75  925  603 1002 1941 2230   41  861 2175\n",
      " 2435  892  486  478 2061  679 2122  811 1388 1459 1384  758 2115  717\n",
      " 1706 1499 1254 2100 1779 1618 1771 2079 1846  718 2229  850 1824 2206\n",
      "  238 1915  417  922 2315  583  563  319 1759 1861 1967  658 1016  482\n",
      "  534 2387  249  551 1690  199 1860  941  163 1138  570  609 2130 2248\n",
      "  522  567  977 2449  881  647  963 1149 1943 1069 1281 2292 1358 2285\n",
      "  993  869 1713  147 1831 1087  277 2400 2179 2191 2277   83 1669 1906\n",
      " 2297 1341 1100 1702  952  466  474 2189  787 1566 1410 1093 1301  623\n",
      " 1288 1688 1420 1899  190  502  671 1839 1055 2188  834 2411 1744 1383\n",
      " 1631 1194 2105 2143  415 1805  237  725  516  255 2346 1044  646 2221\n",
      " 1325 2226  331 2151  705 1165 1748  352  326 2254  499 2178  921  301\n",
      "  164  148 2327 1180 1904 2288 2257  439 1455 1391 1351  694    0  918\n",
      "  948   64 1058  928   84 2110 1199 1415 1722  953  513 1976 2407  785\n",
      "  405  844 1746  813  598 1773 1880   44  673 2224   46  141  821  514\n",
      " 1664  715 2036 1204 1004  343 2008 1377 1324  131 2274    9  569  463\n",
      " 2125 1756  804  739 1565  270 1053 1108 1403 1613 2141 1912  322 1819\n",
      " 1315 1505  882 1238 1385   77 2352 2339  595 2427 1667 1261  116  965\n",
      "   91  504  224 2148 1348  243 1345 1629  495 2256  755  774  714 2412\n",
      " 2372 1811  741 1645 1453  808  167  542  903  846 2093   87 1802 2473\n",
      " 1220 1008 1786  626   58 1303 1905 2075 1808  324 1925 1343 1747 1023\n",
      " 2280 1235 2030  856 2401  854 2333 1477 1560  108  278 1983  226  102\n",
      "  709 1825 2395 1537  661 1144  386  907 1699  492 2441  242  837  911\n",
      "  899 1112    7  628 1958  879 2077 1978   11 2268 1362 1735 2476  653\n",
      "  809 1871 1696  557 2330 1857  678 1798  440 1968 1432  441 2322 1709\n",
      " 2385  333 1593 1503  179 1172 1305  429 2133  121 2020  256 2249 1441\n",
      " 1838 2007  349 1497 1334  337  983  617 1852 1763 1749   21 2058  596\n",
      "  362 2157  769   73  437 1695  193 2072  730 1970 1225 1767 1513 1619\n",
      "  982  884 2375  701 1902 1230 1458 1697 2167 1988 1937  410  173 1454\n",
      "  198 1725 1468 1833 2394 1257 1948 2092  467 1753  230 1154  825 1066\n",
      " 1389  980  287  471 1473  261 1679  296  535  686  555 1171 2162 1567\n",
      "  675 1758 1568  377 1584 1070 1094 1624 1012 1063 1936 1032 2227 1379\n",
      "  508 2418  336 2414 1534 1711  547 2176  142 2119 2010 2282   88  210\n",
      " 2118  571 1704  886 1592 1425 1787  273  938 1272    8  239  431 2069\n",
      "  347 2376 1476 2367 1411 1207 1602 1891 1400  578 1191 1910 2128 1875\n",
      "  395  469  124 1017 1265 2408  157 1994 1182 1107 2234  987 2311 1719\n",
      " 2182 2184  404 2094 1471 2107 1492  645 1308 2006 2154 2018 1930 2068\n",
      " 2003 2102 1675 1878  789  229   20 2377 1755 2265 1591 2121 1321  949\n",
      " 2392   61 2052 2443 1996  209  267  836  614  517 1772 1515 1021 1242\n",
      " 2267 2116 1260  840  957 1859 2343  767 2098   47  843  543 1259 1223\n",
      " 1318 1882  489 1724  143  559 1707 2180 1557 1402 1781  635  991  191\n",
      " 1966 1901 2055   92 2370  592 1330   45 1423 1361  464 1614 1407 1137\n",
      " 2242 1255  768 1493 1347 2126  104 1394   98 1913  711  184 2185  663\n",
      " 1543 1078  582 1582 1374  159 1371 1973 1628 1140 1133 1197 2056 2073\n",
      "  683 2479  985  568 1500  732  175 1164 1770  587 2035 1038  400  406\n",
      "  552  425  798 2260 1845 2351 1538 1286 1430  156 2170 2258 1189 1890\n",
      "   48  176  421  823 2433 2432 2109   19 2198 1665  297  496  317 1328\n",
      " 1186 1295   55 1549 2096 2283 1313  538 1903 2319  509  875 1090  251\n",
      "   96  880  791 1117 1185  306 2444 1163  937 1929  521  564 1927  672\n",
      " 2456 1275  586 1979 2203 1654 1148 2382  874 1807 1202 1003   40 2329\n",
      " 1730 2461   49 1129 1785  346   74 1184  484 1964  556   52 1161 1599\n",
      "  312 2137  453  684 1431  185 1393  323   93  145 2193 2210  339 1322\n",
      "  215 1047 1623 1041 1218  947 2362 2325 2172 2005 1080 1123 1285 1908\n",
      " 1583 1011  677 2271 1609 1158 2497  283 2323  630 1037  851  153 2378\n",
      "  597 2486   95 2278  418  470 1783  448  931  503 1075 2393  364  954\n",
      "  664 1877 1369  540  165 1422  607 1815 1363  468  863  345 1596 1562\n",
      " 2477  692 1306 2366  914  253]\n"
     ]
    }
   ],
   "source": [
    "indices_naive_train = np.argsort(prob_train)[-inspection_capacity_train:] \n",
    "print(indices_naive_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4408aba3-a18e-423f-9730-191e0b24ae43",
   "metadata": {},
   "source": [
    "3. (10 points) Define a mixed-integer optimization problem to minimize the expected costm, i.e., the weighted sum of all the components of the objective, weighted by the defective probabilities. Ensure that the number of inspected products is less than `inspection_capacity`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce8757f",
   "metadata": {},
   "source": [
    "**Solution**\n",
    "For each product $i$, if inspected (i.e., $\\omega_i = 1$), the cost is $c - p^{(i)} s$; otherwise if not inspected (i.e., $\\omega_i = 0$), the cost is $p^{(i)} d$. Therefore, we can formulate the mixed-integer problem below: \n",
    "$$\n",
    "\\begin{array}{ll}\n",
    "    \\text{minimize} & \\sum_{i=1}^{n\\_ shirt} (1-\\omega_i) p^{(i)} d + \\omega_i (c - p^{(i)} s) \\\\\n",
    "    \\text{subject to} & \\sum_{i=1}^{n\\_ shirt} \\omega_i \\leq inspection\\_ capacity\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f274ccf-60af-40d4-8b58-af0ceeb51f93",
   "metadata": {},
   "source": [
    "4. (10 points) Solve and compare both approaches on training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc815630-a13b-495a-a74c-08b7aa8051da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained cost by naive approach:  8167.979670830689\n",
      "Trained cost by MIP approach:  7888.071330607504\n",
      "Test cost by naive approach:  1461.4243552791104\n",
      "Test cost by MIP approach:  1448.2352907704458\n"
     ]
    }
   ],
   "source": [
    "c=10\n",
    "d=20\n",
    "s=15\n",
    "def compute_expected_cost(w, p):\n",
    "    return np.sum(p * d + w * (c - p * (s + d)))\n",
    "\n",
    "# Solve MIP\n",
    "def MIP(X, prob_X):\n",
    "    n_shirt = X.shape[0]\n",
    "    inspection_capacity = int(0.4 * n_shirt)\n",
    "    w = cp.Variable(n_shirt, boolean=True)\n",
    "    expected_cost = cp.sum(d*prob_X + cp.multiply(w, c - (s + d) * prob_X))\n",
    "    objective = cp.Minimize(expected_cost)\n",
    "    constraints = [cp.sum(w) <= inspection_capacity]\n",
    "    problem = cp.Problem(objective, constraints)\n",
    "    problem.solve(solver=cp.SCIPY)\n",
    "    return w.value\n",
    "\n",
    "### Train data\n",
    "n_shirt_train = X_shirt_train.shape[0]\n",
    "prob_train = prob(X_shirt_train, a, b)\n",
    "# Naive approach\n",
    "w_naive_train = np.zeros(n_shirt_train)\n",
    "w_naive_train[indices_naive_train] = 1\n",
    "cost_naive_train = compute_expected_cost(w_naive_train, prob_train)\n",
    "print(\"Trained cost by naive approach: \", cost_naive_train)\n",
    "# MIP approach\n",
    "w_MIP_train = MIP(X_shirt_train, prob_train)\n",
    "cost_MIP_train = compute_expected_cost(w_MIP_train, prob_train)\n",
    "print(\"Trained cost by MIP approach: \", cost_MIP_train)\n",
    "\n",
    "\n",
    "### Test data\n",
    "shirt_indices_test = np.where(y_test == 1)[0]\n",
    "X_shirt_test = X_test[shirt_indices_test]\n",
    "n_shirt_test = X_shirt_test.shape[0]\n",
    "prob_test = prob(X_shirt_test, a, b)\n",
    "# Naive approach\n",
    "w_naive_test = np.zeros(n_shirt_test)\n",
    "inspection_capacity_test = int(0.4 * n_shirt_test)\n",
    "indices_naive_test = np.argsort(prob_test)[-inspection_capacity_test:] \n",
    "w_naive_test[indices_naive_test] = 1\n",
    "cost_naive_test = compute_expected_cost(w_naive_test, prob_test)\n",
    "print(\"Test cost by naive approach: \", cost_naive_test)\n",
    "# MIP approach\n",
    "w_MIP_test = MIP(X_shirt_test, prob_test)\n",
    "cost_MIP_test = compute_expected_cost(w_MIP_test, prob_test)\n",
    "print(\"Test cost by MIP approach: \", cost_MIP_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
